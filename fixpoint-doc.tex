\documentclass{article}

\setlength{\parindent}{0 pt}

\usepackage{fullpage, xspace, enumitem}

\usepackage[pdfborder={.25 .25 .25}]{hyperref}

\urlstyle{rm}

\usepackage{microtype}

\newcommand{\blob}{\textbf{Blob}\xspace}
\newcommand{\blobs}{\textbf{Blob}s\xspace}
\newcommand{\valuex}{\textbf{Value}\xspace}
\newcommand{\valuexs}{\textbf{Value}s\xspace}
\newcommand{\object}{\textbf{Object}\xspace}
\newcommand{\objects}{\textbf{Object}s\xspace}
\newcommand{\encode}{\textbf{Encode}\xspace}
\newcommand{\thunk}{\textbf{Thunk}\xspace}
\newcommand{\thunks}{\textbf{Thunk}s\xspace}
\newcommand{\blobthunk}{\textbf{Blob Thunk}\xspace}
\newcommand{\blobthunks}{\textbf{Blob Thunk}s\xspace}
\newcommand{\treethunk}{\textbf{Tree Thunk}\xspace}
\newcommand{\treethunks}{\textbf{Tree Thunk}s\xspace}
\newcommand{\encodes}{\textbf{Encode}s\xspace}
\newcommand{\name}{\textbf{Name}\xspace}
\newcommand{\names}{\textbf{Name}s\xspace}
\newcommand{\tree}{\textbf{Tree}\xspace}
\newcommand{\trees}{\textbf{Tree}s\xspace}
\newcommand{\pathx}{\textbf{Path}\xspace}
\newcommand{\pathxs}{\textbf{Path}s\xspace}
\newcommand{\bs}{\vspace{\baselineskip}}

\begin{document}
\thispagestyle{empty}

\textbf{Computation in the Fixpoint OS}\newline
Yuhan Deng, Sadjad Fouladi, Keith Winstein (last updated: 1/14/2021)

\bs

Fixpoint is a ``deterministic operating system'' that roughly follows
the design of the SICP
\href{https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-27.html#\%_sec_4.2.2}{``Interpreter
  with Lazy Evaluation''}. The data model is similar to a Git
repository, one that can also represent computational relations
between content-addressed objects: e.g., ``blob \texttt{<x>} is the
output of computation \texttt{<y>} given tree \texttt{<z>} as input.''
The intention is to support a range of applications, including
pre-existing \textsc{posix} programs, and for the OS to provide
``determinism-safety'': program execution is referentially
transparent, and irreproducibility is considered an OS bug, even
across different computers.\footnote{Not \emph{everything} can be
referentially transparent---IO has to happen somewhere. Fixpoint does have a
context where IO is permitted, akin to an ``unsafe'' block in Rust,
but the intention is to let programmers and users constrain and
delimit the non-deterministic parts of a program, rather than allowing
unrestricted IO to happen anywhere.} We envision cloud-computing
providers offering ``computation as a service'': the customer provides
a description of a computation, and the provider returns the answer
for a fee, perhaps backed by an insurance policy that guarantees
correctness.

%\vspace{0.5\baselineskip}
%{\Large \textbf{1. Types}}

\section{Types}

\subsection{\objects, \valuexs, and \thunks}

The basic type is an \object. Each \object is immutable, has one canonical representation, and is either:

\begin{itemize}[itemsep=0pt]
\item a \valuex, which is either:
\begin{itemize}[itemsep=0pt]
  \item a \blob: a vector of bytes, or

  \item a \tree: a vector of entries, each containing:

    \begin{enumerate}[topsep=0pt, itemsep=0pt]
    \item a \name, and

    \item a boolean indicating whether the entry is ``strict'' or ``lazy,''
    \end{enumerate}
\end{itemize}

\item or a \thunk, which represents a particular \valuex by specifying
  a way to compute it. Internally, a \thunk contains the \name of an \encode.
\end{itemize}

\object identity is defined by equality of the canonical representation.

\subsection{\names}

A \name identifies a particular \object by means of an unambiguous
reference, either:
    \begin{itemize}[itemsep=0pt]
    \item a ``canonical name'': the \textsc{sha-256} hash of the \object's canonical representation, or
    \item a ``local name'': a locally generated unique ID that identifies an \object
    \item a ``literal'': the \object itself.
    \end{itemize}

\names are opaque; two \names that identify the same \object are equivalent for purposes of computation.

\subsection{\encodes}

An \encode\footnote{For ``Explicit Named Computation On Data or
\encodes.''} is a \tree that describes the application of a function
to inputs, producing an \object as output. The first entry specifies the
function, which is either:
\begin{itemize}[itemsep=0pt]
\item A \blob that contains a Wasm module, or
\item An \encode.
\end{itemize}

The second entry describes the resource limits at runtime (e.g.,
pages of mutable memory).

\bs

At evaluation-time, the function has access to the \encode. A strict
entry designates a \valuex that the function can read. A lazy entry
refers to an \object that the function can include in its output (as a
lazy or strict entry), without being able to read its
contents.\footnote{This can support functions that do short-circuit
evaluation, e.g. ``\texttt{if}'' or ``\texttt{and},'' while retaining
the referential transparency of \thunks for their corresponding
\valuexs. That is, without full-blown \texttt{fexprs}.}

\bs

We chose Wasm as the basic representation of computation because (1)
LLVM can compile into it, which lets many existing programs and
languages be used, (2) it can run at near-native speed, both in terms
of throughput ($>85\%$ of native) and invocation latency ($<$~100~ns),
and (3) it's possible to guarantee that computations are
deterministic, at least within a microarchitectural
family\footnote{One of the few sources of nondeterminism in Wasm is
the freedom for the underlying microarchitecture, e.g.~x86-64 or \textsc{arm}, to represent floating-point NaNs
with different bitwise representations.}

\section{State}

The system maintains several global mappings:
\begin{itemize}[itemsep=0pt]
\item The ``storage'' maps a \name to the contents of the corresponding \object.

\item The ``memoization cache'' maps a \thunk to the \name of an \object that represents
  a reduction of the original \thunk. This target may be either another \thunk, or the referred-to \valuex.

\item The ``trace cache'' maps a \name to a human-readable string.
\end{itemize}

\section{Operations}

\begin{quote}
\begin{quote}
\textit{It has been said that the principal function of an operating system
is to define a number of different names for the same object, so that it
can  busy  itself  keeping  track of the relationship between all of the
different names.} (David Clark, 1982\footnote{\href{https://www.rfc-editor.org/rfc/rfc814.html}{RFC 814}.})
\end{quote}
\end{quote}

\subsection{Forcing}

``Forcing'' is an function from \objects to \valuexs:

\begin{itemize}[itemsep=0pt]
\item Forcing a \blob is the identity operation.

\item Forcing a \tree forces each of its strict entries, replacing the
  entry's \name field with the \name of the resulting \valuex.

\item Forcing a \thunk recursively reduces it to its referred-to \valuex.
\end{itemize}

\subsection{Reducing a \thunk (one step)}

``Reducing'' a \thunk transforms it to another \thunk or to the
eventual \valuex. To do this, the system will:
\begin{itemize}[itemsep=0pt]
\item retrieve a memoized reduction from the memoization cache, or
\item compute the reduction, by:
  \begin{enumerate}[topsep=0pt, itemsep=0pt]
  \item evaluating the \encode that the \thunk names,
  \item returning the \encode's output \object, and
  \item optionally inserting an entry into the memoization cache from the \thunk to the output \object.
  \end{enumerate}
\end{itemize}

\subsection{Forcing a \thunk}

Forcing a \thunk means:
\begin{enumerate}[itemsep=0pt]
\item reducing it, and
\item if the resulting \object is a \thunk, forcing that \thunk in turn.
\end{enumerate}

\subsection{Evaluating an \encode}

To evaluate an \encode, the system will:
\begin{enumerate}[itemsep=0pt]
\item force the \encode itself, transforming each strict entry into a \valuex
\item run the Wasm module's entry function, providing it with imported host functions that let it:
\begin{itemize}[itemsep=0pt, topsep=0pt]
\item access any \tree or \blob named in a strict entry of the \encode (and the strict entries of any of those \trees, etc.)
\item create new \objects (including \trees that reference lazy entries of the \encode)
\item designate an \object as its output, and
\item steal the storage backing an accessible \valuex and mutate it to create a new \valuex\footnote{The OS
might implement this by making a copy of the \valuex, or by actually allowing
the function to mutate the only copy---based on a guess that the \valuex won't be referenced
again and can be recomputed-on-demand if that guess is wrong.}.
\end{itemize}
\end{enumerate}

The storage is never \emph{required} to compute the \textsc{sha-256} hash of an
\object. However, to avoid storing duplicate long-lived \valuexs, the
runtime will probably choose to hash any long-lived \object that is
identified by a literal key (including a \thunk), and replace the key
with the canonical name. If the original key was a \thunk, this can be
moved to an entry in the memoization cache.

\section{Examples}

\textbf{Example I: Simple addition.} To add two numbers (e.g., 4 and
7), the user can create an \texttt{add} function in Wasm that expects
two inputs and writes one output. (We sometimes refer to the first or
sole output as the value ``returned'' by the \encode, but a \thunk can
reference any output.)  The user inserts this function into the
storage under its canonical name (the \textsc{sha-256} hash of the Wasm
module).

The user then writes an \encode where:
\begin{enumerate}[itemsep=0pt]
\item The function is the canonical name of the Wasm module (with the appropriate function index)
\item The two strict inputs are the literal \blob ``4'' and the literal \blob ``7''
\end{enumerate}
The user inserts this \encode into the storage under its canonical
name (the \textsc{sha-256} hash of the \encode).

The user then writes a \thunk referring to the just-inserted \encode and output index \#0, and asks Fixpoint
to force it. The result will be a \blob with the contents ``11''.

\textbf{Example II: Input dependencies.} To compile and link a C program with two source files,
the build system can create three \encodes:
\begin{enumerate}[itemsep=0pt]
\item An \encode that preprocesses, compiles, and assembles the first source file to a \texttt{.o} file
  (the \texttt{.c} file and all system headers are in the strict input \tree)
\item An \encode that does the same to produce the second \texttt{.o} file
\item An \encode that links the \texttt{.o} files and produces an executable. The strict inputs will include \thunks corresponding to the output of the first two \encodes, plus all necessary libraries.
\end{enumerate}

When the user forces a \thunk that refers to the output of the last \encode, the system will need to force
the strict input \tree before applying the function. This can compile each source file in parallel before linking.

\textbf{Example III: Tail recursion.} To compute the $n$th Fibonacci number
recursively, the user can write a \texttt{fib} function that
takes one numerical argument.
\begin{itemize}[itemsep=0pt]
\item \texttt{fib(1)} returns ``1''
\item \texttt{fib(2)} returns ``1''
  \item \texttt{fib(n)} (for $n>2$) creates three \encodes
    representing \texttt{fib(n-1)}, \texttt{fib(n-2)}, and
    \texttt{add} applied to the outputs of the previous two, and
    returns a \thunk referring to the output of the \texttt{add}
    \encode.
    \end{itemize}

If the user forces a \thunk referring to the output of \texttt{fib(200)}, the system will
evaluate the \encode and the output will be another \thunk---which it will then force, in turn,
until finally reaching a \blob answer.

\textbf{Example IV: map operator.} The \texttt{map} function expects
two lazy inputs: the function $f$, and a \tree being mapped over.  It
returns a \tree where each entry is a \thunk representing the application of $f$ to the corresponding
entry in the mapped-over \tree.

\textbf{Example V: special forms.} To implement an \texttt{if}
operator, the user writes a function that expects one strict
input (the predicate) and two lazy inputs (the consequent and
alternative), and writes one output.

The function examines the contents of the ``predicate'' input,
interpreting it with whatever representation the user (or their
programming language) prefers. If true, the function writes a \thunk
that refers to its ``consequent'' input. Otherwise, the function
writes a \thunk that refers to its ``alternative'' input.

\textbf{Example VI: short-circuiting ``and''.} To implement a
short-circuiting \texttt{and} operator, the user writes a function
that expects one strict input and one lazy input, and writes
one output. The function returns a \thunk that expresses \texttt{if(\#0,
  if(\#1, true, false), false)}.

\textbf{Example VII: currying.} The \texttt{curry} function transforms
a function $f$ of two arguments into a function $h$ of one argument,
whose value is another function $g$ of one argument such that $h(x)(y) =
g(y) = f(x,y)$.

To implement this, the user creates two Wasm functions: \texttt{curry} and \texttt{partial-apply}.

The \texttt{curry} function expects one strict input, corresponding to
$f$.  The output is an \encode representing $h$. The function is
\texttt{partial-apply} and there is one strict input, naming $f$. The
\texttt{partial-apply} function expects two strict inputs,
representing $f$ and $x$. The output is an \encode representing
$g$. The function is $f$, and there is one strict input, naming $x$.

Because \encodes can be used as functions and the inputs are appended,
this allows the result of \texttt{curry($f$)} to be used as a function
applied to $x$, which in turn can be applied to $y$. The inputs could
also be provided in a different order, in which case the $g$ function would
need to return a thunk that reorders the inputs before giving them to
the original $f$.

\section{Open questions}

\begin{enumerate}[itemsep=0pt]
\item What is the latency overhead for a ``safe'' Wasm invocation, compared with a pure native function,
  and compared with forking a process on Linux?

\item What is the throughput overhead of running a C or C++ program
  that was compiled by \texttt{clang} into Wasm $\rightarrow$
  \texttt{wasm2c} $\rightarrow$ \texttt{libclang} $\rightarrow$
  \texttt{x86-64} ELF object, compared with compiling by \texttt{clang}
  directly into an \texttt{x86-64} ELF executable?

\item How to handle I/O (random numbers, time, filesystem and network access, user interaction)

\item When/how to garbage-collect from the storage or memoization cache

\item How to share reproducible computations between users---perhaps by extending the Git on-disk format?
  
\item Execution policy language separate from definition of a
  computation (to describe data placement / parallelization policy,
  garbage-collection policy, and when to give read-write access to
  inputs to a function because a \valuex will not be referenced again)

\item Does the approach to lazy inputs really ensure that a \thunk can
  always be replaced by (1) any other \thunk that refers to the same
  \valuex, or (2) the referred-to \valuex, without ever altering the
  result of a computation? (We don't want a function to be able to
  know if the runtime has or hasn't applied some optimization.) Does
  the system also successfully prevent cyclic references (e.g., two \thunks that resolve to
  each other)?

\item Can we run \texttt{clang.wasm} within Fixpoint, to compile
  \texttt{clang} into Wasm, to make the system self-hosting? Can we bootstrap an entire Linux distribution
  this way (perhaps following the Guix bootstrap dependency graph)?
 
\item \ldots
  
\end{enumerate}

\end{document}
