\documentclass{article}

\setlength{\parindent}{0 pt}

\usepackage{fullpage, xspace, enumitem}

\usepackage[pdfborder={.25 .25 .25}]{hyperref}

\urlstyle{rm}

\usepackage{microtype}

\newcommand{\blob}{\textbf{Blob}\xspace}
\newcommand{\blobs}{\textbf{Blob}s\xspace}
\newcommand{\valuex}{\textbf{Value}\xspace}
\newcommand{\valuexs}{\textbf{Value}s\xspace}
\newcommand{\object}{\textbf{Object}\xspace}
\newcommand{\objects}{\textbf{Object}s\xspace}
\newcommand{\encode}{\textbf{Encode}\xspace}
\newcommand{\thunk}{\textbf{Thunk}\xspace}
\newcommand{\thunks}{\textbf{Thunk}s\xspace}
\newcommand{\blobthunk}{\textbf{Blob Thunk}\xspace}
\newcommand{\blobthunks}{\textbf{Blob Thunk}s\xspace}
\newcommand{\treethunk}{\textbf{Tree Thunk}\xspace}
\newcommand{\treethunks}{\textbf{Tree Thunk}s\xspace}
\newcommand{\encodes}{\textbf{Encode}s\xspace}
\newcommand{\name}{\textbf{Name}\xspace}
\newcommand{\names}{\textbf{Name}s\xspace}
\newcommand{\tree}{\textbf{Tree}\xspace}
\newcommand{\trees}{\textbf{Tree}s\xspace}
\newcommand{\pathx}{\textbf{Path}\xspace}
\newcommand{\pathxs}{\textbf{Path}s\xspace}
\newcommand{\bs}{\vspace{\baselineskip}}

\begin{document}
\thispagestyle{empty}

\textbf{Computation in the Fixpoint OS}\newline
Yuhan Deng, Sadjad Fouladi, Keith Winstein (last updated: 12/24/2021)

\bs

Fixpoint is a ``deterministic operating system'' that roughly follows
the design of the SICP
\href{https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-27.html#\%_sec_4.2.2}{``Interpreter
  with Lazy Evaluation''}. The data model is similar to a Git
repository, one that can also represent computational relations
between content-addressed objects: e.g., ``blob \texttt{<x>} is the
output of computation \texttt{<y>} given tree \texttt{<z>} as input.''
The intention is to support a range of applications, including
pre-existing \textsc{posix} programs, and for the OS to provide
``determinism-safety'': program execution is referentially
transparent, and irreproducibility is considered an OS bug, even
across different computers.\footnote{Not \emph{everything} can be
referentially transparent---IO has to happen somewhere. Fixpoint has a
context where IO is permitted, akin to an ``unsafe'' block in Rust,
but the intention is to let programmers and users constrain and
delimit the non-deterministic parts of a program, rather than allowing
unrestricted IO to happen everywhere.} We envision cloud-computing
providers offering ``computation as a service'': the customer provides
a description of a computation, and the provider returns the answer
for a fee, perhaps backed by an insurance policy that guarantees
correctness.

%\vspace{0.5\baselineskip}
%{\Large \textbf{1. Types}}

\section{Types}

\subsection{\objects, \valuexs, and \thunks}

The basic type is an \object. Each \object is immutable, has one canonical representation, and is either:

\begin{itemize}[itemsep=0pt]
\item a \valuex, which is either:
\begin{itemize}[itemsep=0pt]
  \item a \blob: a vector of bytes, or

  \item a \tree: a vector of entries, each containing:

    \begin{enumerate}[topsep=0pt, itemsep=0pt]
    \item a \name, and

    \item a boolean indicating whether the entry is ``strict'' or ``lazy,''
    \end{enumerate}
\end{itemize}

\item or a \thunk, which represents a particular \valuex by specifying
  a way to compute it. Internally, a \thunk contains the \name of an \encode.
\end{itemize}
  
\subsection{\names}

A \name is a structure that identifies an \object. A \name contains:
\begin{enumerate}[itemsep=0pt]
  \item a human-readable string, and
  \item an unambiguous reference to a particular object, either:
    \begin{itemize}[itemsep=0pt]
    \item a ``canonical name'': the {\textsc SHA-256} hash of the \object's canonical representation, or
    \item a ``literal'': the canonical representation of the \object itself.
    \end{itemize}
\end{enumerate}

\enlargethispage{3\baselineskip}

\subsection{\encodes}

An \encode\footnote{For ``Explicit Named Computation On Data or
\encodes.''} is a \tree that describes the application of a function
to inputs, producing an \object as output. The first entry specifies the
function, which is either:
\begin{itemize}[itemsep=0pt]
\item A \blob that contains a Wasm module, or
\item An \encode.
\end{itemize}

The rest of the \encode's entries specify the inputs. A strict entry
designates a \valuex that will be available to the function at
runtime. A lazy entry designates an \object that the function can
include in its output (as a lazy or strict entry), without being able
to read its contents.\footnote{This can support functions that do
short-circuit evaluation, e.g. ``\texttt{if}'' or ``\texttt{and},''
while retaining the referential transparency of \thunks for their corresponding \valuexs. That
is, without full-blown \texttt{fexprs}.}

\bs

We chose Wasm as the basic representation of computation because (1)
LLVM can compile into it, which lets many existing programs and
languages be used, (2) it can run at near-native speed, both in terms
of throughput ($>85\%$ of native) and invocation latency ($<$~100~ns),
and (3) it's possible to guarantee that computations are
deterministic, at least within a microarchitectural
family\footnote{One of the few sources of nondeterminism in Wasm is
the freedom for the underlying microarchitecture, e.g.~x86-64 or ARM, to represent floating-point NaNs
with different bitwise representations.}

\section{State}

The system maintains two global mappings:
\begin{itemize}[topsep=0pt, itemsep=0pt]
\item The ``storage'' maps a canonical name (SHA-256 hash) to the contents of the corresponding \object.

\item The ``memoization cache'' maps a \thunk to a set of \names, all
  of which refer to the same \valuex and are reductions of the
  original \thunk. Ideally this set includes the \name of the
  referred-to \valuex.
\end{itemize}
  
\section{Operations}

\subsection{Forcing}

``Forcing'' is an operation from \objects to \valuexs.

\begin{itemize}[itemsep=0pt]
\item Forcing a \blob is the identity operation.

\item Forcing a \tree forces each of its \emph{strict} entries, optionally in
  parallel, replacing the entry's name with the \name of the resulting \valuex.

\item Forcing a \thunk resolves it to its referred-to \valuex.
\end{itemize}

\subsection{Reducing a \thunk (one step)}

``Reducing'' a \thunk (one step) transforms it either to another \thunk of the same type, or to the eventual \valuex itself. To reduce a \thunk, the system will:
\begin{itemize}[itemsep=0pt]
\item retrieve a memoized reduction from the memoization cache, or
\item compute the reduction, by:
  \begin{enumerate}[itemsep=0pt]
  \item evaluating the \encode that the \thunk names
  \item selecting the output \tree (if a \treethunk) or the first entry in the output \tree (if a \blobthunk)

  \item optionally inserting entries into the memoization cache for each of the \encode's outputs, and
  \item retrieving the identified output
  \end{enumerate}
\end{itemize}

Then forcing the output recursively until a \valuex is the result.

To ``evaluate'' an \encode, the system will:
\begin{enumerate}[itemsep=0pt]
\item force the \encode's strict input \tree, transforming each input into a \valuex
\item apply the function to its inputs. This means running the Wasm module's first function and letting it:
\begin{itemize}[itemsep=0pt]
\item read the strict input \tree and retrieve any \valuex referred to
\item modify the contents of any strict input\footnote{The function doesn't
  know whether the runtime is implementing this by making a copy of
  the input, or by allowing the function to mutate its only copy
  (based on a guess that the \valuex won't be referenced again
  and can be recomputed if needed).}
\item add arbitrary \objects to the output \tree, with an arbitrary \pathx
\item copy lazy inputs to arbitrary \pathxs in the output \tree
\end{itemize}
\end{enumerate}

The storage is never \emph{required} to compute the SHA-256 hash of an
\object. However, to avoid storing duplicate long-lived \valuexs, the
runtime will probably choose to hash any long-lived \object that is
identified by a literal key (including a \thunk), and replace the key
with the canonical name. If the original key was a \thunk, this can be
moved to an entry in the memoization cache.

\section{Examples}

\textbf{Example I: Simple addition.} To add two numbers (e.g., 4 and
7), the user can create an \texttt{add} function in Wasm that expects
two inputs and writes one output. (We sometimes refer to the first or
sole output as the value ``returned'' by the \encode, but a \thunk can
reference any output.)  The user inserts this function into the
storage under its canonical name (the SHA-256 hash of the Wasm
module).

The user then writes an \encode where:
\begin{enumerate}[itemsep=0pt]
\item The function is the canonical name of the Wasm module (with the appropriate function index)
\item The two strict inputs are the literal \blob ``4'' and the literal \blob ``7''
\end{enumerate}
The user inserts this \encode into the storage under its canonical
name (the SHA-256 hash of the \encode).

The user then writes a \thunk referring to the just-inserted \encode and output index \#0, and asks Fixpoint
to force it. The result will be a \blob with the contents ``11''.

\textbf{Example II: Input dependencies.} To compile and link a C program with two source files,
the build system can create three \encodes:
\begin{enumerate}[itemsep=0pt]
\item An \encode that preprocesses, compiles, and assembles the first source file to a \texttt{.o} file
  (the \texttt{.c} file and all system headers are in the strict input \tree)
\item An \encode that does the same to produce the second \texttt{.o} file
\item An \encode that links the \texttt{.o} files and produces an executable. The strict inputs will include \thunks corresponding to the output of the first two \encodes, plus all necessary libraries.
\end{enumerate}

When the user forces a \thunk that refers to the output of the last \encode, the system will need to force
the strict input \tree before applying the function. This can compile each source file in parallel before linking.

\textbf{Example III: Tail recursion.} To compute the $n$th Fibonacci number
recursively, the user can write a \texttt{fib} function that
takes one numerical argument.
\begin{itemize}[itemsep=0pt]
\item \texttt{fib(1)} returns ``1''
\item \texttt{fib(2)} returns ``1''
  \item \texttt{fib(n)} (for $n>2$) creates three \encodes
    representing \texttt{fib(n-1)}, \texttt{fib(n-2)}, and
    \texttt{add} applied to the outputs of the previous two, and
    returns a \thunk referring to the output of the \texttt{add}
    \encode.
    \end{itemize}

If the user forces a \thunk referring to the output of \texttt{fib(200)}, the system will
evaluate the \encode and the output will be another \thunk---which it will then force, in turn,
until finally reaching a \blob answer.

\textbf{Example IV: map operator.} The \texttt{map} function expects
two lazy inputs: the function $f$, and a \tree being mapped over.  It
returns a \tree where each entry is a \thunk representing the application of $f$ to the corresponding
entry in the mapped-over \tree.

\textbf{Example V: special forms.} To implement an \texttt{if}
operator, the user writes a function that expects one strict
input (the predicate) and two lazy inputs (the consequent and
alternative), and writes one output.

The function examines the contents of the ``predicate'' input,
interpreting it with whatever representation the user (or their
programming language) prefers. If true, the function writes a \thunk
that refers to its ``consequent'' input. Otherwise, the function
writes a \thunk that refers to its ``alternative'' input.

\textbf{Example VI: short-circuiting ``and''.} To implement a
short-circuiting \texttt{and} operator, the user writes a function
that expects one strict input and one lazy input, and writes
one output. The function returns a \thunk that expresses \texttt{if(\#0,
  if(\#1, true, false), false)}.

\textbf{Example VII: currying.} The \texttt{curry} function transforms
a function $f$ of two arguments into a function $h$ of one argument,
whose value is another function $g$ of one argument such that $h(x)(y) =
g(y) = f(x,y)$.

To implement this, the user creates two Wasm functions: \texttt{curry} and \texttt{partial-apply}.

The \texttt{curry} function expects one strict input, corresponding to
$f$.  The output is an \encode representing $h$. The function is
\texttt{partial-apply} and there is one strict input, naming $f$. The
\texttt{partial-apply} function expects two strict inputs,
representing $f$ and $x$. The output is an \encode representing
$g$. The function is $f$, and there is one strict input, naming $x$.

Because \encodes can be used as functions and the inputs are appended,
this allows the result of \texttt{curry($f$)} to be used as a function
applied to $x$, which in turn can be applied to $y$. The inputs could
also be provided in a different order, in which case the $g$ function would
need to return a thunk that reorders the inputs before giving them to
the original $f$.

\section{Open questions}

\begin{enumerate}[itemsep=0pt]
\item What is the latency overhead for a ``safe'' Wasm invocation, compared with a pure native function,
  and compared with forking a process on Linux?

\item What is the throughput overhead of running a C or C++ program
  that was compiled by \texttt{clang} into Wasm $\rightarrow$
  \texttt{wasm2c} $\rightarrow$ \texttt{libclang} $\rightarrow$
  \texttt{x86-64} ELF object, compared with compiling by \texttt{clang}
  directly into an \texttt{x86-64} ELF executable?

\item How to handle I/O (random numbers, time, filesystem and network access, user interaction)

\item When/how to garbage-collect from the storage or memoization cache

\item How to share reproducible computations between users---perhaps by extending the Git on-disk format?
  
\item Execution policy language separate from definition of a
  computation (to describe data placement / parallelization policy,
  garbage-collection policy, and when to give read-write access to
  inputs to a function because a \valuex will not be referenced again)

\item Does the approach to lazy inputs really ensure that a \thunk can
  always be replaced by (1) any other \thunk that refers to the same
  \valuex, or (2) the referred-to \valuex, without ever altering the
  result of a computation? (We don't want a function to be able to
  know if the runtime has or hasn't applied some optimization.) Does
  the system also successfully prevent cyclic references (e.g., two \thunks that resolve to
  each other)?

\item Can we run \texttt{clang.wasm} within Fixpoint, to compile
  \texttt{clang} into Wasm, to make the system self-hosting? Can we bootstrap an entire Linux distribution
  this way (perhaps following the Guix bootstrap dependency graph)?
 
\item \ldots
  
\end{enumerate}

\end{document}
