\documentclass{article}

\setlength{\parindent}{0 pt}

\usepackage{fullpage, xspace, enumitem}

\usepackage[pdfborder={.25 .25 .25}]{hyperref}

\urlstyle{rm}

\usepackage{microtype}

\newcommand{\blob}{\textbf{Blob}\xspace}
\newcommand{\blobs}{\textbf{Blob}s\xspace}
\newcommand{\valuex}{\textbf{Value}\xspace}
\newcommand{\valuexs}{\textbf{Value}s\xspace}
\newcommand{\object}{\textbf{Object}\xspace}
\newcommand{\objects}{\textbf{Object}s\xspace}
\newcommand{\encode}{\textbf{Encode}\xspace}
\newcommand{\thunk}{\textbf{Thunk}\xspace}
\newcommand{\thunks}{\textbf{Thunk}s\xspace}
\newcommand{\blobthunk}{\textbf{Blob Thunk}\xspace}
\newcommand{\blobthunks}{\textbf{Blob Thunk}s\xspace}
\newcommand{\treethunk}{\textbf{Tree Thunk}\xspace}
\newcommand{\treethunks}{\textbf{Tree Thunk}s\xspace}
\newcommand{\encodes}{\textbf{Encode}s\xspace}
\newcommand{\name}{\textbf{Name}\xspace}
\newcommand{\names}{\textbf{Name}s\xspace}
\newcommand{\tree}{\textbf{Tree}\xspace}
\newcommand{\trees}{\textbf{Tree}s\xspace}
\newcommand{\pathx}{\textbf{Path}\xspace}
\newcommand{\pathxs}{\textbf{Path}s\xspace}
\newcommand{\bs}{\vspace{\baselineskip}}

\begin{document}
\thispagestyle{empty}

\textbf{Computation in the Fixpoint OS}\newline
Yuhan Deng, Sadjad Fouladi, Keith Winstein (last updated: 1/14/2021)

\bs

Fixpoint is a ``deterministic operating system'' that roughly follows
the design of the SICP
\href{https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-27.html#\%_sec_4.2.2}{``Interpreter
  with Lazy Evaluation''}. The data model is similar to a Git
repository, one that can also represent computational relations
between content-addressed objects: e.g., ``blob \texttt{<x>} is the
output of computation \texttt{<y>} given tree \texttt{<z>} as input.''
The intention is to support a range of applications, including
pre-existing \textsc{posix} programs, and for the OS to provide
``determinism-safety'': program execution is referentially
transparent, and irreproducibility is considered an OS bug, even
across different computers.\footnote{Not \emph{everything} can be
referentially transparent---IO has to happen somewhere. Fixpoint does have a
context where IO is permitted, akin to an ``unsafe'' block in Rust,
but the intention is to let programmers and users constrain and
delimit the non-deterministic parts of a program, rather than allowing
unrestricted IO to happen anywhere.} We envision cloud-computing
providers offering ``computation as a service'': the customer provides
a description of a computation, and the provider returns the answer
for a fee, perhaps backed by an insurance policy that guarantees
correctness.

%\vspace{0.5\baselineskip}
%{\Large \textbf{1. Types}}

\section{Types}

\subsection{\objects, \valuexs, and \thunks}

The basic type is an \object. Each \object is immutable, has one canonical representation, and is either:

\begin{itemize}[itemsep=0pt]
\item a \valuex, which is either:
\begin{itemize}[itemsep=0pt]
  \item a \blob: a vector of bytes, or

  \item a \tree: a vector of entries, each containing:

    \begin{enumerate}[topsep=0pt, itemsep=0pt]
    \item a \name, and

    \item a boolean indicating whether the entry is ``strict'' or ``lazy,''
    \end{enumerate}
\end{itemize}

\item or a \thunk, which represents a particular \valuex by specifying
  a way to compute it. Internally, a \thunk contains the \name of an \encode.
\end{itemize}

\object identity is defined by equality of the canonical representation.

\subsection{\names}

A \name is a string that identifies a particular \object by means of an unambiguous
reference, either:
    \begin{itemize}[itemsep=0pt]
    \item a ``canonical name'': the \textsc{sha-256} hash of the \object's canonical representation,
    \item a ``local name'': a locally generated unique ID that identifies an \object, or
    \item a ``literal'': the canonical representation of the \object itself.
    \end{itemize}

\names are opaque; two \names that identify the same \object are equivalent for purposes of computation.

\subsection{\encodes}

An \encode\footnote{For ``Explicit Named Computation On Data or
\encodes.''} is a \tree that describes the application of a function
to inputs, producing an \object as output. The first entry specifies
the resource limits at runtime (e.g., maximum pages of mutable memory). The second entry
species the function, which is either:
\begin{itemize}[itemsep=0pt]
\item A \blob that contains a Wasm module, or
\item An \encode.
\end{itemize}

At evaluation-time, the function can read any ``accessible \valuex'' in
the \encode---which means any strict entry of the \encode, and any
strict entry of an ``accessible'' \tree. A lazy entry refers to an
\object that the function can include in its output (as a lazy or
strict entry), without being able to read its contents.\footnote{This
can support functions that do short-circuit evaluation,
e.g. ``\texttt{if}'' or ``\texttt{and},'' while retaining the
referential transparency of \thunks for their corresponding
\valuexs. That is, without full-blown \texttt{fexprs}.}

\bs

We chose Wasm as the basic representation of computation because (1)
LLVM can compile into it, which lets many existing programs and
languages be used, (2) it can run at near-native speed, both in terms
of throughput ($>85\%$ of native) and invocation latency ($<$~100~ns),
and (3) it's possible to guarantee that computations are
deterministic, at least within a microarchitectural
family\footnote{One of the few sources of nondeterminism in Wasm is
the freedom for the underlying microarchitecture, e.g.~x86-64 or \textsc{arm}, to represent floating-point NaNs
with different bitwise representations.}

\section{State}

The system maintains several global mappings:
\begin{itemize}[itemsep=0pt]
\item The ``storage'' maps a \name to the contents of the corresponding \object.

\item The ``memoization cache'' maps a \thunk to the \name of an \object that represents
  a reduction of the original \thunk. This target may be either another \thunk, or the referred-to \valuex.

\item The ``trace cache'' maps a \name to a human-readable string.
\end{itemize}

\section{Operations}

\begin{quote}
\begin{quote}
\textit{It has been said that the principal function of an operating system
is to define a number of different names for the same object, so that it
can  busy  itself  keeping  track of the relationship between all of the
different names.} (David Clark, 1982\footnote{\href{https://www.rfc-editor.org/rfc/rfc814.html}{RFC 814}.})
\end{quote}
\end{quote}

\subsection{Forcing}

``Forcing'' is an function from \objects to \valuexs:

\begin{itemize}[itemsep=0pt]
\item Forcing a \blob is the identity operation.

\item Forcing a \tree forces each of its strict entries, replacing the
  entry's \name field with the \name of the resulting \valuex.

\item Forcing a \thunk recursively reduces it to its referred-to \valuex.
\end{itemize}

\subsection{Reducing a \thunk (one step)}

``Reducing'' a \thunk transforms it to another \thunk or to the
eventual \valuex. To do this, the system will:
\begin{itemize}[itemsep=0pt]
\item retrieve a memoized reduction from the memoization cache, or
\item compute the reduction, by:
  \begin{enumerate}[topsep=0pt, itemsep=0pt]
  \item evaluating the \encode that the \thunk names,
  \item returning the \encode's output \object, and
  \item optionally inserting an entry into the memoization cache from the \thunk to the output \object.
  \end{enumerate}
\end{itemize}

\subsection{Forcing a \thunk}

Forcing a \thunk means:
\begin{enumerate}[itemsep=0pt]
\item reducing it, and
\item if the resulting \object is a \thunk, forcing that \thunk in turn.
\end{enumerate}

\subsection{Evaluating an \encode}

To evaluate an \encode, the system will:
\begin{enumerate}[itemsep=0pt]
\item force the \encode itself, transforming each strict entry into a \valuex
\item run the Wasm module's entry function, providing it with imported host functions that let it:
\begin{itemize}[itemsep=0pt, topsep=0pt]
\item access any ``accessible \valuex'' from the \encode,
\item create new \objects (including \trees that reference lazy inputs),
\item designate an \object as its output,
\item steal the storage backing an accessible \valuex and mutate it to create a new \valuex\footnote{The OS
might implement this by making a copy of the \valuex, or by actually allowing
the function to mutate the only copy---based on a guess that the \valuex won't be referenced
again and can be recomputed-on-demand if that guess is wrong.}, and
\item insert entries into the trace cache that attach human-readable names to the \objects it creates.
\end{itemize}
\end{enumerate}

The storage is never \emph{required} to compute the \textsc{sha-256} hash of an
\object. However, to avoid storing duplicate long-lived \valuexs, the
runtime will probably choose to hash any long-lived \object that is
identified by a literal key (including a \thunk), and replace the key
with the canonical name. If the original key was a \thunk, this can be
moved to an entry in the memoization cache.

\section{Examples}

\subsection{Simple addition} To add two numbers (e.g., 4 and
7), the user can create an \texttt{add} function in Wasm that expects
two \blobs as inputs and writes one \blob as output.

\bs

The user then writes an \encode where:
\begin{enumerate}[itemsep=0pt]
\item The function is the Wasm module
\item The runtime mutable-memory limit is one page
\item The next entries are the literal \blob ``4'' and the literal \blob ``7''
\end{enumerate}

The user then writes a \thunk referring to the just-inserted \encode,
and asks Fixpoint to force it. The result will be a \blob with the
contents ``11''.

\subsection{Dependencies computed in parallel} To compile and link a C program with two source files,
the build system can create three \encodes:
\begin{enumerate}[itemsep=0pt]
\item An \encode that preprocesses, compiles, and assembles the first \texttt{.c} file to a \texttt{.o} file
  (the \texttt{.c} file and system headers are accessible inputs)
\item An \encode that does the same to produce the second \texttt{.o} file from the second \texttt{.c} file
\item An \encode that links the \texttt{.o} files and produces an executable. The strict inputs include \thunks corresponding to the output of the first two \encodes.
\end{enumerate}

When the user forces a \thunk that refers to the last \encode, the
system will need to force the strict inputs before applying the
function. This can compile each source file in parallel before
linking.

\subsection{Tail recursion} To compute the $n$th Fibonacci number
recursively, the user can write a \texttt{fib} function that
takes one numerical argument.
\begin{itemize}[itemsep=0pt]
\item \texttt{fib(1)} returns the \blob ``1''
\item \texttt{fib(2)} returns the \blob ``1''
  \item \texttt{fib(n)} (for $n>2$) creates two \encodes
    representing \texttt{fib(n-1)} and \texttt{fib(n-2)}.
    Then it outputs a \thunk referring to an \encode that represents
    the \texttt{add} function applied to \thunks of the previous two \encodes.
    \end{itemize}

If the user forces a \thunk referring to the output of \texttt{fib(200)}, the system will
evaluate the \encode and the output will be another \thunk---which it will then force, in turn,
until finally reaching a \blob answer.

\subsection{Unix-like directories and Git-like trees}

In Unix directories and Git trees, each entry has a human-readable
name associated with it. In Fixpoint, \tree entries are unnamed. (Two
\trees that refer to the same \objects in the same order are the same
\tree.) A Unix- or Git-like filesystem could be represented in a
Fixpoint \tree by storing a name-to-index mapping in the first entry,
followed by the actual entries. Fixpoint would be agnostic to the
precise representation of the name-to-index mapping.

\subsection{map operator} The \texttt{map} function expects
two inputs: the function $f$, and a \tree of lazy entries to be mapped
over. It returns a \tree where each entry is a \thunk representing the
application of $f$ to the corresponding entry in the mapped-over
\tree.

\subsection{special forms} To implement an \texttt{if}
operator, the user writes a function that expects one strict input
(the predicate) and two lazy inputs (the consequent and alternative),
and writes one output.

\bs

The function examines the contents of the ``predicate'' input,
interpreting it with whatever representation the user (or their
programming language) prefers. If true, the function outputs its
``consequent'' input. Otherwise, the function outputs its
``alternative'' input.

\subsection{short-circuiting ``and''} To implement a
short-circuiting \texttt{and} operator, the user writes a function
that expects one strict input and any number of lazy inputs.

\begin{itemize}[itemsep=0pt]
\item \texttt{and()} returns \texttt{true}
\item \texttt{and($x$)} returns the truth value of $x$
\item \texttt{and($x$, $y$, \ldots)} returns \texttt{false} if $x$ is false, or otherwise returns a \thunk referring to an 
\encode representing \texttt{and($y$, \ldots)} where $y$ has been rewritten as a strict entry.
\end{itemize}

\subsection{currying} The \texttt{curry} function transforms
a function $f$ of two arguments into a function $h$ of one argument,
whose value is another function $g$ of one argument such that $\texttt{curry}(f) = h$, $h(x) = g$, and $g(y) = f(x,y)$.

\bs

To implement this, the user creates two Wasm functions: \texttt{curry}
and \texttt{partial-apply}. The \texttt{curry} function expects one
input corresponding to $f$. The output is an \encode representing
$h$, in which the function is \texttt{partial-apply}
with an additional entry naming $f$.

\bs

The user can now construct an \encode representing $h(x) = g$, in
which the function entry is the $h$ \encode, and an \encode
representing $g(y)$, in which the function entry is the $g$
\encode. When evaluated, the \texttt{partial-apply} function finds the
$f$ \valuex deep within the $h$ \encode, the $x$ \valuex within the
$g$ \encode, and the $y$ \valuex within the top-level $g(y)$ \encode.
Its output is a \thunk representing the output of a new \encode: $f(x,y)$.

\section{Open questions}

\begin{enumerate}[itemsep=0pt]
\item What is the latency overhead for a ``safe'' Wasm invocation, compared with a pure native function,
  and compared with forking a process on Linux?

\item What is the throughput overhead of running a C or C++ program
  that was compiled by \texttt{clang} into Wasm $\rightarrow$
  \texttt{wasm2c} $\rightarrow$ \texttt{libclang} $\rightarrow$
  \texttt{x86-64} ELF object, compared with compiling by \texttt{clang}
  directly into an \texttt{x86-64} ELF executable?

\item What should be the precise ``Fixpoint API'' exposed to Wasm via imported host functions that lets a function read the accessible \valuexs, create new \objects,
  create \trees that refer to recently created \objects, etc.?
  
\item What should be the additional API surface for an ``IO-Encode,'' e.g.~how to handle random numbers, time, filesystem and network access, user interaction?

\item How to implement the WASI API in a Wasm module, in terms of the Fixpoint API?
  
\item When/how to garbage-collect from the storage or memoization and trace caches?

\item How to share reproducible computations between users---perhaps by extending the Git on-disk format?
  
\item Execution strategy language separate from definition of a
  computation (to describe data placement / parallelization policy,
  garbage-collection policy, etc.)?
  
\item Does the approach to lazy inputs really ensure that a \thunk can
  always be replaced by (1) any other \thunk that refers to the same
  \valuex, or (2) the referred-to \valuex, without ever altering the
  result of a computation? (We don't want a function to be able to
  know if the runtime has or hasn't applied some optimization.) Does
  the system also successfully prevent cyclic references (e.g., two \thunks that resolve to
  each other)?

\item Can we run \texttt{clang.wasm} within Fixpoint, to compile
  \texttt{clang} into Wasm, to make the system self-hosting? Can we bootstrap an entire Linux distribution
  this way, perhaps following the Guix bootstrap dependency graph?

\item What's the right API for higher-level languages (e.g., Rust or C++) to expose constructs like, e.g.~a parallel map that compiles into an \encode with many inputs?

\item What should a ``visual debugger'' look like to inspect the computation flow and provenance of computed outputs?
  
\item \ldots
  
\end{enumerate}

\end{document}
